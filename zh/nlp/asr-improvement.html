

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>教程 &mdash; nemo 0.8.1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../_static/jquery.js"></script>
        <script type="text/javascript" src="../_static/underscore.js"></script>
        <script type="text/javascript" src="../_static/doctools.js"></script>
        <script type="text/javascript" src="../_static/language_data.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="NeMo Collections API" href="../collections/modules.html" />
    <link rel="prev" title="Tutorial" href="joint_intent_slot_filling.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> nemo
          

          
          </a>

          
            
            
              <div class="version">
                0.8.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../index.html">简介</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">如何安装</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorials/intro.html">从这里开始</a></li>
<li class="toctree-l1"><a class="reference internal" href="../training.html">快速训练</a></li>
<li class="toctree-l1"><a class="reference internal" href="../asr/intro.html">语音识别</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="intro.html">自然语言处理</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="intro.html#nmt">神经网络机器翻译 (NMT)</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#bert">BERT</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#transformer">Transformer语言模型</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#id2">命名实体识别</a></li>
<li class="toctree-l2"><a class="reference internal" href="intro.html#intent-and-slot-filling">Intent and Slot filling</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="intro.html#bertx2">用BERTx2后处理模型来提升语音识别性能</a><ul class="current">
<li class="toctree-l3 current"><a class="current reference internal" href="#">教程</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id3">数据</a></li>
<li class="toctree-l4"><a class="reference internal" href="#bert">从预训练BERT模型中加载参数</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id7">神经模块概览</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">模型训练</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id10">参考</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../collections/modules.html">NeMo Collections API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api-docs/modules.html">NeMo API</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">nemo</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="intro.html">自然语言处理</a> &raquo;</li>
        
      <li>教程</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/nlp/asr-improvement.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="id1">
<h1>教程<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>在这个教程中，我们会训练一个语音识别的后处理模型来纠正端到端语音识别模型的输出错误。这个模型和翻译模型很相似，但和传统语音识别模型的再打分很不一样。
这个模型的架构是基于注意力机制的编码器解码器架构，其中编码器和解码器都是用BERT的预训练语言模型初始化的。为了训练这个模型，我们用预训练的Jasper语音识别模型 <a class="bibtex reference internal" href="../zh/nlp/asr-improvement.html#li2019jasper" id="id2">[1]</a> 产生的错误来收集数据集。</p>
<div class="section" id="id3">
<h2>数据<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p><strong>数据收集</strong> 我们用Jasper <a class="bibtex reference internal" href="../zh/nlp/asr-improvement.html#li2019jasper" id="id4">[1]</a>  在Librispeech数据集 <a class="bibtex reference internal" href="../zh/nlp/asr-improvement.html#panayotov2015librispeech" id="id5">[3]</a> 上训练的模型为这个任务收集数据集。
下载Librispeech数据集, 参考 <a class="reference internal" href="../zh/asr/datasets.html#librispeech-dataset"><span class="std std-ref">LibriSpeech</span></a>.
获得Jasper预训练模型, 参考 <a class="reference internal" href="../zh/asr/jasper.html#jasper-model"><span class="std std-ref">Jasper</span></a>.
Librispeech训练数据集包含三个部分: train-clean-100, train-clean-360, 和train-clean-500 总共281000个训练样本 .
我们用两个方法来扩增数据集:</p>
<ul class="simple">
<li><p>我们把所有的训练集分成10份，然后用交叉验证的方法训练10个Jasper模型: 一个模型在9份数据集上训练，然后再剩下的那份数据集上做语音识别.</p></li>
<li><p>我们用预训练的Jasper模型，在训练集上做推理的时候，打开dropout。这个过程用不同的随机种子重复多次。</p></li>
</ul>
<p><strong>数据后处理</strong> 收集到的数据集需要去除重复以及错词率大于0.5的样本。
得到的数据集包含1,700,000对 “坏” 英文-“好” 英文样本对。</p>
<p><strong>开发和测试集准备</strong>. Librispeech包含两个开发集
(dev-clean 和 dev-other) 以及2个测试 (test-clean 和 test-other).
在我们的任务中，我们也这么分。我们把这些数据集放到预训练好的Jasper模型中，用greedy解码得到语音识别的输出结果。这些结果
在我们的教程中用来做评测。</p>
</div>
<div class="section" id="bert">
<h2>从预训练BERT模型中加载参数<a class="headerlink" href="#bert" title="Permalink to this headline">¶</a></h2>
<p>编码器和解码器都用的是预训练的BERT模型参数。 因为BERT的语言模型和Transformer的编码器结构相同，因此没有其他什么需要做的。从预训练的BERT模型中为解码器准备参数，我们写了一个脚本 <code class="docutils literal notranslate"><span class="pre">get_decoder_params_from_bert.py</span></code> 会从 <code class="docutils literal notranslate"><span class="pre">pytorch-transformers</span></code> <a class="bibtex reference internal" href="../zh/nlp/asr-improvement.html#huggingface2019transformers" id="id6">[1]</a> 下载参数，并把他们映射到解码器的参数上.
编码器和解码器的注意力是用self-attention参数做初始化的。
这个脚本位于 <code class="docutils literal notranslate"><span class="pre">scripts</span></code> 文件目录下，接受两个参数:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">--model_name</span></code>: e.g. <code class="docutils literal notranslate"><span class="pre">bert-base-cased</span></code>, <code class="docutils literal notranslate"><span class="pre">bert-base-uncased</span></code>, etc.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">--save_to</span></code>: 参数将要存储的文件目录</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python get_decoder_params_from_bert.py --model_name bert-base-uncased
</pre></div>
</div>
</div></blockquote>
</li>
</ul>
</div>
<div class="section" id="id7">
<h2>神经模块概览<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>首先，因为所有的模块都是由NeMo构建的, 我们需要初始化Neural Module Factory，我们需要定义 1) backend (PyTorch 还是 TensorFlow), 2) 混精度优化等级, 3) GPU的loca rank, 以及 4) 一个实验管理器，创建一个时间戳的文件夹来存储checkpoints和相关的输出，日志文件以及TensorBoard的图.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">nf</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">NeuralModuleFactory</span><span class="p">(</span>
                <span class="n">backend</span><span class="o">=</span><span class="n">nemo</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">Backend</span><span class="o">.</span><span class="n">PyTorch</span><span class="p">,</span>
                <span class="n">local_rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">,</span>
                <span class="n">optimization_level</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">amp_opt_level</span><span class="p">,</span>
                <span class="n">log_dir</span><span class="o">=</span><span class="n">work_dir</span><span class="p">,</span>
                <span class="n">create_tb_writer</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                <span class="n">files_to_copy</span><span class="o">=</span><span class="p">[</span><span class="vm">__file__</span><span class="p">])</span>
</pre></div>
</div>
</div></blockquote>
<p>接着我们定义分词器把所有的词转到它们对应的序号上. 我们会使用 <code class="docutils literal notranslate"><span class="pre">bert-base-uncased</span></code> 模型的词表， 因为我们的数据集只包含不区分大小写的文本:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">NemoBertTokenizer</span><span class="p">(</span><span class="n">pretrained_model</span><span class="o">=</span><span class="s2">&quot;bert-base-uncased&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>编码器模块对应于BERT的语言模型，它来自于
<code class="docutils literal notranslate"><span class="pre">nemo_nlp.huggingface</span></code> collection:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">zeros_transform</span> <span class="o">=</span> <span class="n">nemo</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">pytorch</span><span class="o">.</span><span class="n">common</span><span class="o">.</span><span class="n">ZerosLikeNM</span><span class="p">()</span>
<span class="n">encoder</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">huggingface</span><span class="o">.</span><span class="n">BERT</span><span class="p">(</span>
    <span class="n">pretrained_model_name</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">pretrained_model</span><span class="p">,</span>
    <span class="n">local_rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>让词嵌入的大小（包括其他的张量维度）能够整除8可以得到最好的GPU利用率和混精度训练加速。</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">vocab_size</span> <span class="o">=</span> <span class="mi">8</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">/</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">tokens_to_add</span> <span class="o">=</span> <span class="n">vocab_size</span> <span class="o">-</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">vocab_size</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">encoder</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">get_device</span><span class="p">()</span>
<span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">tokens_to_add</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>

<span class="n">encoder</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span>
    <span class="p">(</span><span class="n">encoder</span><span class="o">.</span><span class="n">bert</span><span class="o">.</span><span class="n">embeddings</span><span class="o">.</span><span class="n">word_embeddings</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">zeros</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
<p>接着, 我们构建transformer解码器神经模块. 因为我们会用BERT预训练的参数来初始化我们的解码器, 我们设置隐藏层激活函数为 <code class="docutils literal notranslate"><span class="pre">&quot;hidden_act&quot;:</span> <span class="pre">&quot;gelu&quot;</span></code> 以及设置学习位置编码 <code class="docutils literal notranslate"><span class="pre">&quot;learn_positional_encodings&quot;:</span> <span class="pre">True</span></code>:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nemo_nlp</span><span class="o">.</span><span class="n">TransformerDecoderNM</span><span class="p">(</span>
    <span class="n">d_model</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
    <span class="n">d_inner</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">d_inner</span><span class="p">,</span>
    <span class="n">num_layers</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
    <span class="n">num_attn_heads</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span>
    <span class="n">ffn_dropout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">ffn_dropout</span><span class="p">,</span>
    <span class="n">vocab_size</span><span class="o">=</span><span class="n">vocab_size</span><span class="p">,</span>
    <span class="n">max_seq_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">max_seq_length</span><span class="p">,</span>
    <span class="n">embedding_dropout</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">embedding_dropout</span><span class="p">,</span>
    <span class="n">learn_positional_encodings</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">hidden_act</span><span class="o">=</span><span class="s2">&quot;gelu&quot;</span><span class="p">,</span>
    <span class="o">**</span><span class="n">dec_first_sublayer_params</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>为了把预训练参数加载到解码器参数中, 我们用解码器神经模块的属性函数 <code class="docutils literal notranslate"><span class="pre">restore_from</span></code> 来加载:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">decoder</span><span class="o">.</span><span class="n">restore_from</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">restore_from</span><span class="p">,</span> <span class="n">local_rank</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">local_rank</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="id8">
<h2>模型训练<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h2>
<p>训练模型，运行 <code class="docutils literal notranslate"><span class="pre">asr_postprocessor.py.py</span></code>， 它位于 <code class="docutils literal notranslate"><span class="pre">examples/nlp</span></code> 目录中. 我们用novograd优化器来训练  <a class="bibtex reference internal" href="../zh/nlp/asr-improvement.html#ginsburg2019stochastic" id="id9">[2]</a>, 设置学习率 <code class="docutils literal notranslate"><span class="pre">lr=0.001</span></code> ，多项式学习率衰减策略, <code class="docutils literal notranslate"><span class="pre">1000</span></code> 步预热, 每个GPU的批量为 <code class="docutils literal notranslate"><span class="pre">4096*8</span></code> 符号, 以及 <code class="docutils literal notranslate"><span class="pre">0.25</span></code> dropout概率. 我们再8张GPU上做训练。可以用下面的方法开启多GPU训练模式:</p>
<blockquote>
<div><div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$ python -m torch.distributed.launch --nproc_per_node<span class="o">=</span><span class="m">8</span>  asr_postprocessor.py --data_dir ../../tests/data/pred_real/ --restore_from ../../scripts/bert-base-uncased_decoder.pt
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="id10">
<h2>参考<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h2>
<p id="bibtex-bibliography-nlp/asr-improvement-0"><dl class="citation">
<dt class="bibtex label" id="huggingface2019transformers"><span class="brackets"><a class="fn-backref" href="#id6">1</a></span></dt>
<dd><p>A library of state-of-the-art pretrained models for natural language processing (nlp). <span><a class="reference external" href="#"></a></span>https://github.com/huggingface/pytorch-transformers, Accessed August 23, 2019.</p>
</dd>
<dt class="bibtex label" id="ginsburg2019stochastic"><span class="brackets"><a class="fn-backref" href="#id9">2</a></span></dt>
<dd><p>Boris Ginsburg, Patrice Castonguay, Oleksii Hrinchuk, Oleksii Kuchaiev, Vitaly Lavrukhin, Ryan Leary, Jason Li, Huyen Nguyen, and Jonathan M Cohen. Stochastic gradient methods with layer-wise adaptive moments for training of deep networks. <em>arXiv preprint arXiv:1905.11286</em>, 2019.</p>
</dd>
<dt class="bibtex label" id="li2019jasper"><span class="brackets">1</span><span class="fn-backref">(<a href="#id2">1</a>,<a href="#id4">2</a>)</span></dt>
<dd><p>Jason Li, Vitaly Lavrukhin, Boris Ginsburg, Ryan Leary, Oleksii Kuchaiev, Jonathan M Cohen, Huyen Nguyen, and Ravi Teja Gadde. Jasper: an end-to-end convolutional neural acoustic model. <em>arXiv preprint arXiv:1904.03288</em>, 2019.</p>
</dd>
<dt class="bibtex label" id="panayotov2015librispeech"><span class="brackets"><a class="fn-backref" href="#id5">3</a></span></dt>
<dd><p>Vassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech: an asr corpus based on public domain audio books. In <em>2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em>, 5206–5210. IEEE, 2015.</p>
</dd>
</dl>
</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../collections/modules.html" class="btn btn-neutral float-right" title="NeMo Collections API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="joint_intent_slot_filling.html" class="btn btn-neutral float-left" title="Tutorial" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2018-2019, AI Applications team

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>